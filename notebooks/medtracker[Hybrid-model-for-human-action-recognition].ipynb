{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jjyPrEkQZV"
      },
      "source": [
        "## **Action Net Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s0bX0Rb5TKQy",
        "outputId": "92a29858-8a28-4bc0-9d9a-5d54da28917f"
      },
      "outputs": [],
      "source": [
        "# # ENV: python==3.6.13 AND tensorflow==2.4.4\n",
        "# # \n",
        "# # pip install tensorflow==2.4.4 && pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0 && pip install imageai==2.1.6\n",
        "# # \n",
        "# !pip install tensorflow==2.4.4\n",
        "# !pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0\n",
        "# !pip install imageai==2.1.6\n",
        "# \n",
        "# # !pip install imageai\n",
        "# # \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jcz0J8roTPBW"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import requests\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from imageai.Prediction.Custom import ModelTraining, CustomImagePrediction\n",
        "import os\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ABPbqC6CTlGg"
      },
      "outputs": [],
      "source": [
        "# \n",
        "execution_path = os.getcwd()\n",
        "# \n",
        "SOURCE_PATH = \"https://github.com/OlafenwaMoses/Action-Net/releases/download/v1/action_net_v1.zip\"\n",
        "FILE_DIR = os.path.join(execution_path, \"action_net_v1.zip\")\n",
        "DATASET_DIR = os.path.join(execution_path, \"action_net_v1.zip\")\n",
        "# \n",
        "# https://github.com/OlafenwaMoses/Action-Net/releases/download/v1/action_net_ex-060_acc-0.745313.h5\n",
        "# https://huggingface.co/datasets/Bingsu/Human_Action_Recognition\n",
        "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6631238/\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlJPu43XeAsD",
        "outputId": "ef5232d7-d4e2-4c5c-f4dd-38c05c632344"
      },
      "outputs": [],
      "source": [
        "# if not exists('action_net_ex-060_acc-0.745313.h5'):\n",
        "#   !wget https://raw.githubusercontent.com/OlafenwaMoses/Action-Net/master/model_class.json\n",
        "#   !wget https://github.com/OlafenwaMoses/Action-Net/releases/download/v1/action_net_ex-060_acc-0.745313.h5\n",
        "#   # \n",
        "#   !git clone https://github.com/OlafenwaMoses/Action-Net\n",
        "#   !mkdir images && cp -r Action-Net/images ./images\n",
        "#   # !unzip images.zip -d ./\n",
        "# # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bLPmW_RyTl_3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def download_action_net():\n",
        "    if (os.path.exists(FILE_DIR) == False):\n",
        "        print(\"Downloading action_net_v1.zip\")\n",
        "        data = requests.get(SOURCE_PATH,\n",
        "                            stream=True)\n",
        "\n",
        "        with open(FILE_DIR, \"wb\") as file:\n",
        "            shutil.copyfileobj(data.raw, file)\n",
        "        del data\n",
        "\n",
        "        extract = ZipFile(FILE_DIR)\n",
        "        extract.extractall(execution_path)\n",
        "        extract.close()\n",
        "\n",
        "\n",
        "def train_action_net():\n",
        "    download_action_net()\n",
        "\n",
        "    trainer = ModelTraining()\n",
        "    trainer.setModelTypeAsResNet()\n",
        "    trainer.setDataDirectory(\"action_net_v1\")\n",
        "    trainer.trainModel(num_objects=16, num_experiments=200, batch_size=32, save_full_model=True,\n",
        "                       enhance_data=True)\n",
        "\n",
        "def run_predict(image_file_path: str = \"images/5.jpg\"):\n",
        "    predictor = CustomImagePrediction()\n",
        "    predictor.setModelPath(model_path=\"action_net_ex-060_acc-0.745313.h5\")\n",
        "    predictor.setJsonPath(model_json=\"model_class.json\")\n",
        "    predictor.loadFullModel(num_objects=16)\n",
        "\n",
        "\n",
        "    # predictions, probabilities = predictor.predictImage(image_input=image_file_path, result_count=4)\n",
        "    predictions, probabilities = predictor.classifyImage(image_input=image_file_path, result_count=4)\n",
        "    # for prediction, probability in zip(predictions, probabilities):\n",
        "    #     print(prediction, \" : \", probability)\n",
        "\n",
        "    return predictions, probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsAfojG2UsWR",
        "outputId": "52d66701-708e-4bdd-e5a8-94054391ee3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kissing  :  68.00127625465393\n",
            "laughing  :  15.769656002521515\n",
            "calling  :  14.704068005084991\n",
            "sleeping  :  1.4966920018196106\n"
          ]
        }
      ],
      "source": [
        "#Un-comment the line below to train the model\n",
        "#train_action_net()\n",
        "\n",
        "#Un-comment the line below to run predictions\n",
        "predictions, probabilities = run_predict(\"images/k3.jpg\")\n",
        "for prediction, probability in zip(predictions, probabilities):\n",
        "    print(prediction, \" : \", probability)\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A0t2wKV2ZT6Z"
      },
      "outputs": [],
      "source": [
        "# https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/\n",
        "# https://pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/\n",
        "# \n",
        "# \n",
        "# Detect air sound from audio and video github\n",
        "# \n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from video2images import Video2Images\n",
        "from application.main.config import settings\n",
        "from application.main.utility.manager.image_utils import BasicImageUtils\n",
        "\n",
        "\n",
        "class BasicVideoUtils(BasicImageUtils):\n",
        "\n",
        "    @classmethod\n",
        "    async def read_video_file(cls, file, filename, cache=True) -> List[Image.Image]:\n",
        "        file_input_location = os.path.join(settings.APP_CONFIG.CACHE_DIR, f\"inputs/{filename}\")\n",
        "        file_output_location = os.path.join(settings.APP_CONFIG.CACHE_DIR, \"outputs\")\n",
        "\n",
        "        # Save video to a temporary file\n",
        "        with open(file_input_location, 'wb') as f:\n",
        "            f.write(file)\n",
        "        \n",
        "        # \n",
        "        try:\n",
        "            # \n",
        "            frames_location = Video2Images(video_filepath=file_input_location, out_dir=file_output_location, capture_rate=10).out_dir\n",
        "            # \n",
        "            images = []\n",
        "            for filename in os.listdir(frames_location):\n",
        "                if filename.endswith('.jpg'):\n",
        "                    # send the file path\n",
        "                    img_path = os.path.join(frames_location, filename)\n",
        "                    images.append(img_path)\n",
        "                    # \n",
        "                    # send the file bytes \n",
        "                    # image = cls.read_image_file(img_path, filename)\n",
        "                    # images.append(image)\n",
        "                    # with Image.open(BytesIO(img_path)) as img:\n",
        "                    #     images.append(img)\n",
        "        except:\n",
        "            return []\n",
        "        \n",
        "        if cache:\n",
        "            pass\n",
        "\n",
        "        return images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from imageai.Prediction.Custom import CustomImagePrediction\n",
        "# \n",
        "# from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "from application.initializer import LoggerInstance\n",
        "# from PIL import Image\n",
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "import ssl\n",
        "# \n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "logger = LoggerInstance().get_logger(__name__)\n",
        "classifier_model = None\n",
        "\n",
        "\n",
        "def merge_dicts(dicts_list):\n",
        "    \"\"\"\n",
        "        To merge a list of dictionaries while taking the mean of values for repeated keys\n",
        "    \"\"\"\n",
        "    merged_dict = defaultdict(lambda: {'sum': 0, 'count': 0})\n",
        "    for d in dicts_list:\n",
        "        for k, v in d.items():\n",
        "            merged_dict[k]['sum'] += v\n",
        "            merged_dict[k]['count'] += 1\n",
        "    mean_dict = {k: v['sum'] / v['count'] for k, v in merged_dict.items()}\n",
        "    return mean_dict\n",
        "\n",
        "\n",
        "class InferenceTask:\n",
        "    \"\"\"\n",
        "        Split video into frames, classify each frame, and ensemble the results\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    async def load_model(classifier_model_name):\n",
        "        if len(classifier_model_name) != 0:\n",
        "            model = CustomImagePrediction()\n",
        "            model.setModelPath(model_path=classifier_model_name['model']) # \"action_net_ex-060_acc-0.745313.h5\"\n",
        "            model.setJsonPath(model_json=classifier_model_name['classes']) # \"model_class.json\" https://raw.githubusercontent.com/OlafenwaMoses/Action-Net/master/model_class.json\n",
        "            model.loadFullModel(num_objects=16)\n",
        "\n",
        "        return model\n",
        "    \n",
        "    @staticmethod\n",
        "    async def decode_results(results: List[zip]) -> List[Dict[str, float]]:\n",
        "        # Dict[str, float]\n",
        "        decoded_results = []\n",
        "        # decoded_results = {}\n",
        "        for result in results:\n",
        "            _results = []\n",
        "            for prediction, probability in result:\n",
        "                resp = {}\n",
        "                resp[prediction] = probability\n",
        "                # resp[\"confidence\"] = probability # f\"{round(probability, 2):0.2f} %\"\n",
        "                _results.append(resp) \n",
        "            # \n",
        "            # print(_results)\n",
        "            _merged_results = merge_dicts(_results)\n",
        "            decoded_results.append(_merged_results)\n",
        "\n",
        "        merged_results = merge_dicts(decoded_results)\n",
        "        return merged_results\n",
        "    \n",
        "    async def predict(self, classifier_model_name, video: List[Path]) -> List:\n",
        "        if len(video) is 0:\n",
        "            return {\"message\": \"Server failed to process file\"}\n",
        "        # \n",
        "        global classifier_model\n",
        "        if classifier_model is None:\n",
        "            classifier_model = await self.load_model(classifier_model_name)\n",
        "        # \n",
        "        results = []\n",
        "        # \n",
        "        for image in video:\n",
        "            predictions, probabilities = classifier_model.classifyImage(image_input=image, result_count=5)\n",
        "            results.append(zip(predictions, probabilities))\n",
        "\n",
        "        response = await self.decode_results(results) # f\"{round(probability, 2):0.2f} %\"\n",
        "        return response\n",
        "# \n",
        "# \n",
        "# https://github.com/AbhishekSalian/Video2Images\n",
        "# https://github.com/bhimrazy/Image-Recognition-App-using-FastAPI-and-PyTorch\n",
        "# \n",
        "# \n",
        "# def run_predict(image_file_path: str = \"images/5.jpg\"):\n",
        "#     predictor = CustomImagePrediction()\n",
        "#     predictor.setModelPath(model_path=\"action_net_ex-060_acc-0.745313.h5\")\n",
        "#     predictor.setJsonPath(model_json=\"model_class.json\")\n",
        "#     predictor.loadFullModel(num_objects=16)\n",
        "\n",
        "\n",
        "#     # predictions, probabilities = predictor.predictImage(image_input=image_file_path, result_count=4)\n",
        "#     predictions, probabilities = predictor.classifyImage(image_input=image_file_path, result_count=4)\n",
        "#     # for prediction, probability in zip(predictions, probabilities):\n",
        "#     #     print(prediction, \" : \", probability)\n",
        "\n",
        "#     return predictions, probabilities\n",
        "# \n",
        "# https://stackoverflow.com/questions/36758945/how-to-merge-a-list-of-dicts-summing-values-for-repeated-keys\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VideoClassificationService(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = LoggerInstance().get_logger(__name__)\n",
        "        self.video_model = InferenceTask()\n",
        "        self.image_classification_model = settings.APP_CONFIG.ACTION_NET_IMAGE_CLASSIFICATION_MODEL\n",
        "        self.image_classification_model_classes = settings.APP_CONFIG.ACTION_NET_IMAGE_CLASSIFICATION_MODEL_CLASSES\n",
        "\n",
        "    async def classify(self, video_data):\n",
        "        self.logger.info(f'Model IN use : {self.image_classification_model}')\n",
        "        label = await self.video_model.predict(classifier_model_name={\"model\": self.image_classification_model, \"classes\": self.image_classification_model_classes}, video=video_data)\n",
        "        return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'BasicVideoUtils' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-01efa4468d73>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvideo_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mawait\u001b[0m \u001b[0mvideo_classification_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BasicVideoUtils' is not defined"
          ]
        }
      ],
      "source": [
        "video_classification_service = VideoClassificationService()\n",
        "# \n",
        "video = await BasicVideoUtils.read_video_file(content, filename=file.filename, cache=True)\n",
        "video_category = await video_classification_service.classify(video)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "actionnet",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4a002a972ffed2979fbf7eb40dece3cf403db33000eef83f43e890e8d0dd126b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
